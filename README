Here‚Äôs your **README** for the Stable Diffusion CLI tool‚Äîclean, link-free, and enriched with accurate citations from Hugging Face documentation to support technical choices.

---

# üñºÔ∏è Stable Diffusion CLI ‚Äî README

## ‚ú® What Is This?

A lightweight Python command-line tool that converts a text prompt into an AI-generated image using Stable Diffusion via the Hugging Face *diffusers* library. You run it with a prompt‚Äîno UI, just straightforward generation, saving, and displaying of the result.

---

## üéØ Why I Made It

* To explore integrating the **StableDiffusionPipeline** for text-to-image generation.
* To automatically use GPU or CPU depending on system availability.
* To experiment with precision settings (using `float16` where possible for faster inference).
* To practice handling saved output, console feedback, and optional enhancements.

---

## ‚úÖ What It Does

* Takes a prompt from the command-line when you run:

  ```bash
  python generate_image.py "a creative prompt here"
  ```

* If no prompt is given, it prints usage instructions and exits.

* Detects GPU availability:

  * Uses `float16` precision and moves the model to GPU if available.
  * Otherwise runs in `float32` on CPU.

* Loads the Stable Diffusion pipeline from Hugging Face using `from_pretrained()`, which automatically selects the correct pipeline type and components for inference. ([GitHub][1], [Hugging Face][2], [Hugging Face][3], [GitHub][4], [Hugging Face][5])

* Optionally sets precision via `torch_dtype=torch.float16` to speed up inference and reduce memory usage. ([GitHub][4])

* Generates one image, saves it as `generated_image.png`, and opens with default image viewer.

* Prints a confirmation message in the terminal.

---

## üß† Technical Highlights

* The `DiffusionPipeline` API wraps all required components‚Äîtext encoder, scheduler, U‚ÄëNet, VAE‚Äîinto one easy-to-use interface. ([Hugging Face][6])
* Precision control using `torch_dtype` helps manage memory and performance. FP16 typically halves memory consumption without much image quality loss. ([Hugging Face][7])
* The default scheduler is `PNDMScheduler`, but you can swap in faster schedulers like `EulerDiscreteScheduler` if needed. ([Hugging Face][8])

---

## üìÇ Suggested File Layout

```
generate_image.py
requirements.txt  (with torch, diffusers, PIL dependency)
README.md
generated_image.png (output file after running)
```

No complex infrastructure‚Äîjust Python 3.8+ and installed packages.

---

## üöÄ Next Steps (Future Enhancements)

* Add command-line flags (`argparse`) for options like:

  * Number of inference steps
  * Seed for reproducibility
  * Scheduler choice
  * Output filename or format
* Use `pipe.enable_attention_slicing()` or `enable_vae_slicing()` to reduce GPU memory usage further on limited hardware. ([Hugging Face][9], [Hugging Face][10], [Hugging Face][7])
* Integrate a minimal Gradio web UI to make the tool usable in the browser. ([Hugging Face][11])
* Support batch prompts, negative prompts, prompt weighting, or custom pre- and post-processing.

---

## ‚úÖ Quick Overview

* Loads Stable Diffusion via Hugging Face `diffusers`
* Chooses GPU with `float16` if available or CPU fallback
* Takes a command-line prompt, generates an image, saves and opens it
* Built for clarity, ease of use, and flexibility for future enhancements

---

